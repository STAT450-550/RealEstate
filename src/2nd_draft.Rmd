---
title: "2nd_draft"
author: "Xuechun Lu, Yuting Wen, Peter Han, Yuetong Liu"
date: "15/03/2020"
output:
  github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
libraries
```{r, message=F, warning=F}
library(tidyverse)
library(ggplot2)
library(dplyr)
library(here)
library(readxl)
library(broom)
library(glmnet)
library(dummies)
```


## Summary


The main objective of our project is to accurately predict future mill rate (property tax) in metro Vancouver for the following 3 property tax classes: Tax class 1: Residential, Tax class 5: Light industry and Tax class 6: Business and other. Data cleaning, exploratory data analysis are used in this project to analyze the relationship between mill rate and other factors. Data cleaning is performed to aggregate our data into summary statistics. Exploratory analysis has shown there are strong relationships between mill rate and tax class and mill rate and municipalities; it has also shown there is a fairly strong correlation between mill rate and average assessment per property in different municipalities. Ordinary linear model, reduced ordinary linear model, Ridge Regression and LASSO are used to predict the mill rate. A full assessment of the performance - prediction power and goodness of fit of these models, is shown below.


## Introduction

Our goal is to predict mill rates in 2020 in the following 22 municipalities:

- Burnaby
- Coquitlam
- Delta
- Langley - City
- Langley - Township
- Maple Ridge
- Maple Ridge Rural
- New Westminster
- North Vancouver - City
- North Vancouver - Dist
- Pitt Meadows
- Port Coquitlam
- Port Moody
- Richmond
- Surrey
- Vancouver
- White Rock
- West Vancouver
- Bowen Island
- Anmore
- Belcarra
- Lions Bay.

We also seek to identify which explanatory variables are the most important in determining mill rates. Every year, the assessment value of each property is released at the beginning of the year, however, the mill rate is still unknown until Spring. Prediction of mill rate is a focus of interest because it gives an approximate property tax to pay for property owners. It is also important because it might affect future buyers’ purchasing incentives. The property tax rate has a fairly small margin to change. Mill rate is adjusted based on the total assessment in each city so the municipal government can use tax earning (total assessment * mill rate) to match their annual expense to balance the city’s budget. 

Correlation between the mill rate and each explanatory variable will be used to pick the essential variables in our model. Then, a variety of linear models will be fitted using our selected variable. The best model is selected based on its prediction power and goodness of fit.



## Data Description

Our client provides us the past 5 years' property assessment data in BC. Since we are only interested in predicting mill rate for metro Vancouver and specific class code, we get a subset of properties that satisfy our interest: 

- TaxClass Code in (01,05,06)
- Municipality in Metro Vancouver

Moreover, we select 5 features that could be relevant to mill rate, which are:

- Tax Year
- Municipality 
- Tax Class
- Assessment Type
- Assessment Value 

There are 1801 missing value in mill rate. 1509 are imputed, and 292 are removed from the data frame. The imputation method is mentioned in appendix. 

Oo reduce the dimension of our data, we aggregate all properties in the same region, classcode, and year are aggregate into a group, becasue these properties have same mill rate,  which is our response variable. Here is the summary statistics for these groups:

- Mill rate 
- Total Assessment 
- Total Land Assessment 
- Total Improvement Assessment 
- Total number of properties 
- Taxclasscode
- Municipality
- Year

## Methods



### Exploratory Analysis


Before any prediction on the future mill rate of Metro Vancouver’s real estate market was made, exploratory data analysis was performed to explore and visualize the main characteristics of our dataset and found relationships between Mill Rate vs. Assessment, Mill Rate vs. Land Total, and Mill Rate vs. Improvement Total were performed. From our initial analysis, outliers in municipalities had been found. Data transformation - calculating the average total assessment, was used to reduce the effect of outliers.

Mill rate is mainly affected by assessment, so scatter plots of mill rate vs. total, land, and improvement assessment were created to see the correlation between each pair of the two factors. Kruskal Wallis analysis was also performed to see the correlation between mill rate vs. tax class and mill rate vs. municipality. 



## TODO modify this part based on the comment in the following link (Leonie)
## _______________________________
https://github.com/STAT450-550/RealEstate/blob/450/doc/Peter_Han_Individual_edit.pdf
### Measure of goodness of fit and prediction power


In this study, we built a few linear models and evaluated their performances by goodness of fit and prediction power, that is, how well the model explains the data and how well it can predict future values. The definition of goodness of fit and prediction power is given below.

 - **Goodness of fit** is defined as the extent to which the sample data are consistent with the model, which examines how well the model explains the data. R squared and adjusted R squared are the most well known measures of goodness of fit and higher R squared and adjusted R squares indicate better goodness of fit. 

 - **Prediction power** measures how well models can predict the future values. We use mean squared prediction power to compare the prediction performance across all of our fitted linear predictive models. To do that, we will divide the data set into training data - used to build our models, and testing data - used to evaluate the prediction power of our models. 


### Linear model


For our linear model, Year, TaxClassCode, Municipalities, Assess Total, Land Assessment Total, Improvement Assessment total, Number of properties and tax (budget) are considered. We first explore the full linear model using all the available features. From our exploratory data analysis, we have found Vancouver, Richmond, Surrey and Burnaby are outliers. Further prediction model will be built based on these findings. We are also intesterd in how different tax class can affect our predictive model, so models based on different tax classes will also be considered in the future. 
For our reduced model, we build our linear predictor using only the significant variables from the full model (See table 4). The reduced model's performence in terms of goodness of fit will decrease with fewer features, however, the performance of prediction power might be improved. 


### Ridge, Lasso and Elastic Net


Other than simple linear regression, we are also interested in the performance of Ridge Regression, Lasso, and Elastic Net. They are more advanced than simple linear regression as they reduce the variance of the model. In these three models, weights are assigned to features. Ridge regression and Lasso take penalty in sum of absolute values and sum of squared absolute values of weights respectively. Elastic net is a combination of Ridge and Lasso.

We build the three models using all features and compare their goodness of fit, and then will examine their prediction power on testing data.
##_____________________________________________

\pagebreak

## Results

###Exploratory Analysis

```{r, warning=F, message=F, echo=FALSE}
## data setup
## Aggregated Data
assessment_aggregate <- read.csv(here("data","assessment_aggregate.csv"))[,-1]
assessment_2020 <- read.csv(here("data","assessment_2020.csv"))[,-1]
# assessment_2020.full <- read_excel(here("data/Assessment", "2020 Only.xlsx"))
```

```{r, echo=FALSE}
## Test correlations between past mill rates and other features.
# ______________________________________________________________________________________________
# CONTINUS variables
assessment_transform <- assessment_aggregate

# log transformation and take avg
assessment_transform[,9] <- assessment_transform$assessTotal/assessment_transform$propertyCount
names(assessment_transform)[9] <- paste("AvgTotalAssessmentValue")

cor(assessment_transform$rate,assessment_transform$AvgTotalAssessmentValue)

assessment_transform %>%
                   ggplot(aes(x=assessTotal,
                              y=rate,group=AddressAssessorMunicipalityDesc,
                              color=AddressAssessorMunicipalityDesc)) + 
                   geom_point() + 
                   ggtitle(sprintf("mill rate vs total assessment value")) + 
                   geom_smooth(aes(group = 1), size = 0.5, method = "lm", se = FALSE, colour = "black")

assessment_transform %>%
                   ggplot(aes(x=landTotal,
                              y=rate,group=AddressAssessorMunicipalityDesc,
                              color=AddressAssessorMunicipalityDesc)) + 
                   geom_point() + 
                   ggtitle(sprintf("mill rate vs total land assessment value")) + 
                   geom_smooth(aes(group = 1), size = 0.5, method = "lm", se = FALSE, colour = "black")
assessment_transform %>%
                   ggplot(aes(x=improvementTotal,
                              y=rate,group=AddressAssessorMunicipalityDesc,
                              color=AddressAssessorMunicipalityDesc)) + 
                   geom_point() + 
                   ggtitle(sprintf("mill rate vs total improvement assessment value")) + 
                   geom_smooth(aes(group = 1), size = 0.5, method = "lm", se = FALSE, colour = "black")

assessment_transform %>%
                   ggplot(aes(x=AvgTotalAssessmentValue,
                              y=rate,group=AddressAssessorMunicipalityDesc,
                              color=AddressAssessorMunicipalityDesc)) + 
                   geom_point() + 
                   ggtitle(sprintf("mill rate vs average total assessment value")) + 
                   geom_smooth(aes(group = 1), size = 0.5, method = "lm", se = FALSE, colour = "black")

# ______________________________________________________________________________________________
# CATEGORICAL variables
for(i in colnames(assessment_transform)[2:3]){
  print(ggplot(assessment_aggregate, aes(x=as.factor(!!as.name(i)),y=rate, fill=as.factor(!!as.name(i)))) + 
  geom_boxplot()+ 
  theme(axis.text.x = element_text(angle = 90, hjust = 1), legend.position = "none"))
}

# kruskal.test
kruskal.test(assessment_transform$rate~assessment_transform$TaxClassCode,data=assessment_transform)
kruskal.test(assessment_transform$rate~assessment_transform$AddressAssessorMunicipalityDesc,data=assessment_transform)
```


## ___________________________
## TODO KW result table, explanation of all plots (Yuting)
## ___________________________



##_____________________________
## TODO modify this part using boxplot and tables, change desrciptions (Leonie)
###Linear Model

**Table 2: Result from Model Used**

<!-- Model | Mutiple R-Squared | Adjusted R_Squared | MSE | PMSE  -->
<!-- ------|--------|--------|--------|-------- -->
<!--       OLR full | 0.8874| 0.8707| 1.9843| 2.5902 -->
<!--       OLR reduced| 0.8874| 0.8721| 1.9845| 2.5237 -->
<!--       Ridge|  0.8868| NA| 1.9896| 2.5675 -->
<!--       LASSO| 0.8873| NA| 1.9855| 2.5280 -->
<!--       Elastic Net| 0.8625| NA| 2.2366| 2.5486 -->


Below is a comparison of the five models (Lasso, Ridge, OLR reduced, OLR full and OLR null) as for goodness of fit and predcition power. Goodness of fit is measured by MSE of the training data, whereas prediction power is measured by MSPE of the testing data. Generally, smaller MSEs and MSPEs indicate better fit and prediction power respectively.

To examine the fit and prediciton power, a 50-run of 10-fold cross validation was performed. For each run, a 10-fold corss validation was used to train the five models and make predictions on training and testing data respectively. Then, the MSEs calculated from the training data and MSPEs calculated from the testing data were stored in vectors of corresponding mdoels. After the 50 runs, a vector of MSEs and a vectors of MSPEs for each model were therefore constructed successfully. 

As for goodness of fit, Lasso, Ridge and OLR reduced have a similar performance; MSEs are around 4.6, but OLR reduced perform slightly better and has a smaller spread (variance) of MSE. OLR full performs worse than the the three, around 5.4, and OLR null has the greatest MSE, around 35.   

Similarly, as for prediction power, Lasso, Ridge and OLR reduced perform roughly the same; MSPEs are close to 6. OLR full is worse with MSPE around 6.9. OLR Null performs the worst with MSPE over 35. 

Therefore, we conclude that from the results of a 50-run of 10-fold cross validation, Lasso, Ridge and OLR reduced have the best goodness of fit and prediction power. OLR null perfroms much worse than all the other four models. 

For a dtailed look of how the models were fitted and evaluated, please refer to the appendix.


```{r, warning=FALSE, echo=FALSE}
## model fitting
set.seed(123)
lambdas <- 10^seq(2, -3, by = -.1)
dummy_municipal<-dummy(assessment_transform$AddressAssessorMunicipalityDesc)
dummy_taxclass<-dummy(assessment_transform$TaxClassCode)

# build x matrix
x<-cbind(dummy_municipal,dummy_taxclass,assessment_transform$AvgTotalAssessmentValue)
y<-assessment_transform$rate
x<-cbind(x,y)

# correct col name
colnames(x)[26]<-c("AvgTotalAssessmentValue")
colnames(x)[27]<-c("rate")
xm<-x[,1:(ncol(x)-1)]
x.data.frame<-assessment_transform
xm.data.frame<-assessment_transform[,-c(1,8,9,10,11)]
y.data.frame<-assessment_transform$rate
n <- nrow(xm)
k <- 10
ii <- (1:n)%%k + 1
N <- 50
mspe1.n<-mspe1.la <- mspe1.f <- mspe1.ri <- mspe1.reduced <- rep(0, N)
mspe.n<-mspe.la <- mspe.f <- mspe.ri <- mspe.reduced <- rep(0, N)

for (i in 1:N) {
  ii <- sample(ii)
  pr1.n<-pr1.la <- pr1.f <- pr1.ri <- pr1.reduced <- rep(0, n)
  pr.n<-pr.la <- pr.f <- pr.ri <- pr.reduced <- rep(0, n)
  for (j in 1:k) {
    # ~ models trained!
    tmp.ri <- cv.glmnet(x = xm[ii != j, ], y = y[ii != j], lambda = lambdas, 
                        nfolds = 10, alpha = 0, family = "gaussian")
    tmp.la <- cv.glmnet(x = xm[ii != j, ], y = y[ii != j], lambda = lambdas, 
                        nfolds = 10, alpha = 1, family = "gaussian")
    tmp.reduced <- lm(rate ~ factor(TaxClassCode)+factor(AddressAssessorMunicipalityDesc)+AvgTotalAssessmentValue, 
                      data = x.data.frame[ii != j, ])
    tmp.full <- lm(rate ~ factor(AddressAssessorMunicipalityDesc)+factor(TaxClassCode)+assessTotal+landTotal+improvementTotal+propertyCount, 
                   data = x.data.frame[ii != j, ])
    tmp.n <- lm(rate ~ 1, 
                      data = x.data.frame[ii != j, ])
    
    # ~ prediction vector on train set
    pr1.ri[ii != j] <- predict(tmp.ri, s = tmp.ri$lambda.min, newx = xm[ii !=
                                                                         j, ])
    pr1.la[ii != j] <- predict(tmp.la, s = tmp.la$lambda.min, newx = xm[ii !=
                                                                         j, ])
    pr1.reduced[ii != j] <- predict(tmp.reduced, newdata = x.data.frame[ii != j, ])
    pr1.f[ii != j] <- predict(tmp.full, newdata = x.data.frame[ii != j, ])
    pr1.n[ii != j] <-predict(tmp.n, newdata = x.data.frame[ii != j, ])
    
    # ~ prediction vector on test set
    pr.ri[ii == j] <- predict(tmp.ri, s = tmp.ri$lambda.min, newx = xm[ii == 
                                                                         j, ])
    pr.la[ii == j] <- predict(tmp.la, s = tmp.la$lambda.min, newx = xm[ii == 
                                                                         j, ])
    pr.reduced[ii == j] <- predict(tmp.reduced, newdata = x.data.frame[ii == j, ])
    pr.f[ii == j] <- predict(tmp.full, newdata = x.data.frame[ii == j, ])
    pr.n[ii == j] <-predict(tmp.n, newdata = x.data.frame[ii == j, ])
    
  }
  
  # goodness of fit
  mspe1.ri[i]<-mean((y - pr1.ri)^2)
  mspe1.la[i]<-mean((y - pr1.la)^2)
  mspe1.reduced[i]<-mean((y - pr1.reduced)^2)
  mspe1.f[i]<-mean((y - pr1.f)^2)
  mspe1.n[i]<-mean((y - pr1.n)^2)
  
  # prediction power
  mspe.ri[i]<-mean((y - pr.ri)^2)
  mspe.la[i]<-mean((y - pr.la)^2)
  mspe.reduced[i]<-mean((y - pr.reduced)^2)
  mspe.f[i]<-mean((y - pr.f)^2)
  mspe.n[i]<-mean((y - pr.n)^2)
}

boxplot(mspe1.la, 
        mspe1.ri, 
        mspe1.reduced, 
        mspe1.f, 
        mspe1.n,
        names = c("LASSO", 
                  "Ridge",
                  "Reduced", 
                  "Full",
                  "Null"
                  ), 
        col = c("steelblue","gray80",
                "pink", 
                "tomato", "springgreen"), 
        cex.axis = 1, 
        cex.lab = 1, 
        cex.main = 2,
        main = "Goodness of Fit",
        ylab = expression(hat(MSE)))

boxplot(mspe.la, 
        mspe.ri,
        mspe.reduced, 
        mspe.f, 
       mspe.n,
        names = c("LASSO", "Ridge", 
                  "Reduced", 
                  "Full",
                  "Null"
                  ), 
        col = c("steelblue","gray80", 
                "pink",
                "tomato", "springgreen"), 
        cex.axis = 1, 
        cex.lab = 1, 
        cex.main = 2,
        main = "Prediction Power",
        ylab = expression(hat(MSPE)))
```
##_______________________________________



##_______________________________________
##TODO: make prediction work for 2020 data (Yuetong)
##(it's missing AvgTotalAssessmentValue, looks like we need to calculate them)
```{r fit, echo=FALSE}
## choose transformed model
linear_1<-lm(rate~factor(AddressAssessorMunicipalityDesc)+factor(TaxClassCode)+AvgTotalAssessmentValue,data=assessment_transform)

## Fit and get PMSE
assessment_2020.agg <- assessment_2020%>%
  mutate(AvgTotalAssessmentValue = assessTotal/propertyCount)%>%
  mutate(predict_rate = predict(linear_1,newdata = .))
resid<-assessment_2020.agg$predict_rate - assessment_2020.agg$rate
sqrt(sum(resid^2)/nrow(assessment_2020.agg))

# ## Final result
# municipality.list = c(
#   "Burnaby", 
#   "Coquitlam", 
#   "Delta", 
#   "Langley - City", 
#   "Langley - Township",
#   "Maple Ridge",
#   "Maple Ridge Rural", 
#   "North Vancouver - City",
#   "North Vancouver - Dist",
#   "Pitt Meadows", 
#   "Port Coquitlam", 
#   "Port Moody", 
#   "Richmond", 
#   "Surrey", 
#   "Vancouver", 
#   "White Rock", 
#   "West Vancouver", 
#   "Bowen Island", 
#   "Anmore", 
#   "Belcarra",
#   "Lions Bay",
#   "New Westminster")
# 
# ## Raw Data
# a <- assessment_2020.full%>%
#   filter(TaxClassCode %in% c("01","05","06"),
#          AddressAssessorMunicipalityDesc %in% municipality.list)

## Aggregate Data
b <- assessment_2020.agg%>%
  select(-c(assessTotal : propertyCount, AvgTotalAssessmentValue))%>%
  mutate(TaxClassCode = as.factor(paste0("0",TaxClassCode)))

# assessment_2020.final<- merge(a, b, by =c("AddressAssessorMunicipalityDesc", "TaxClassCode"), all.x = TRUE)

# write.csv(assessment_2020.final, "../Data/Assessment/assessment_2020.final")
write.csv(b, "../Data/assessment_2020_fit.csv")
``` 




##_____________________________
## TODO: delete pct change part, add prediction based on our chosen model (Peter)
## Conclusion


From our exploratory data analysis, we can see that assessment total, land total, tax code, year and municipalities are all significant in our model. The client suggested that we can transform numerical factors such as assessment total into percentage change. This data transformation does not perform as well as we expected, which only yields an R^2 of around 0.2 across all of our fitted models. We believe the method that the client has suggested might leave out some important information about the housing market in each municipality. We have also found that when comparing the correlation between mill rate against features in our models, Vancouver is an outlier. We would like to further investigate Vancouver as a special case. We are also interested in the effect of different tax classes in predicting mill rate. Further analysis and prediction will be performed based on our hypothesis.

All fitted linear model were able to make accurate prediction based on means squared error, but there is still a very high chance that our model is overfitted. For our next report, we are going to use cross-validation to reduce the effect of overfitting. 
##_______________________________


\pagebreak
## References


Links to source of data: 


- Schedule 706 (https://www2.gov.bc.ca/gov/content/governments/local-governments/facts-framework/statistics/statistics)


Code repository:


- Data Cleaning (https://github.com/STAT450-550/RealEstate/blob/450/src/Data_Cleaning.Rmd)

- Exploratory Data Analysis and Model Fitting (https://github.com/STAT450-550/RealEstate/blob/450/src/EDA%26mode_fitting.Rmd)


##——————————————————————————
##TODO: more styling (Yuting)
##___________________________
## Appendix

##__________________________
## TODO: add one more section: (Yuetong) 
## Include the code relevant to summarizing and aggregating the data from the client, which produces in the dataframe used for analysis.
##__________________________

### Missing Value:

There are 1801 missing values in mill rate(TaxClassTaxRate). We decided to impute these missing values
Based on client information, all properties in the same region, classcode, and year should have a unique class rate

- For entries with mill rate, we aggregated them into groups by region + classcode + year.

- For entries without mill rate, we found the group they belong to and assign them mill rate in that group.

#### Here is some exceptions found:

Some groups' mill rate is not unique:


- In Delta, properties in different neighbourhoods have slightly different mill rates. Since the variance is not significant, we take the mean as the overall mill rate in groups.

- In New Westminister, 2019, Class 06, one property's mill rate is different from others. It is regarded as an outlier.

- In Vancouver, 2019, Class 01, one property's mill rate is different from others. It is regarded as an outlier.

- In Burnaby, 2019, Class 06, six properties' mill rate are different from others. They are regarded as outliers.

- In Langley, 2019, Class 06, mill rate is different between assessment type. After talking to the client, the mill rate for assessment type "land" is regarded as the overall mill rate in that group.

- In some groups, all entries' mill rates are missing. Entries in these groups are removed. Here is the list of the groups:

**Table 3: Data with missing mill rate**

Year  | Region | Class |Number of Properties
------|--------|-------|----------
2016 | Belcarra | 06 | 9 
2016 | Lions Bay | 01 | 40 
2016 | Lions Bay | 06 | 25 
2016 | Maple Ridge Rural | 05 | 36 
2017 | Belcarra | 06 | 9 
2017 | Lions Bay | 01 | 39 
2017 | Lions Bay | 06 | 24 
2017 | Maple Ridge Rural | 05 | 36 
2018 | Maple Ridge Rural | 05 | 36 
2019 | Maple Ridge Rural | 05 | 38
